{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph_Data_Mining_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XCr3A7uAAbjG",
        "ZdqCUqqH7H5Z",
        "RdqOWaDG680t"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMO5tqS7VSV+HOnp3WPg3AP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanujsriv/Graph_Data_Mining_Project/blob/main/Graph_Data_Mining_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_bX15YdQoye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e281f3-752c-4f57-962e-4e4f3c17b107"
      },
      "source": [
        "!wget https://linqs-data.soe.ucsc.edu/public/lbc/citeseer.tgz\n",
        "!tar -xvzf citeseer.tgz\n",
        "# !wget https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
        "# !tar -xvzf cora.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-15 03:08:18--  https://linqs-data.soe.ucsc.edu/public/lbc/citeseer.tgz\n",
            "Resolving linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)... 128.114.47.74\n",
            "Connecting to linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)|128.114.47.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 359425 (351K) [application/x-gzip]\n",
            "Saving to: ‘citeseer.tgz’\n",
            "\n",
            "citeseer.tgz        100%[===================>] 351.00K  1.24MB/s    in 0.3s    \n",
            "\n",
            "2021-05-15 03:08:18 (1.24 MB/s) - ‘citeseer.tgz’ saved [359425/359425]\n",
            "\n",
            "citeseer/\n",
            "citeseer/README\n",
            "citeseer/citeseer.cites\n",
            "citeseer/citeseer.content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCr3A7uAAbjG"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFhfh6vgRde0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt5tXqY1GkuN"
      },
      "source": [
        "# !git clone https://github.com/maxiaoba/GRAPE.git\n",
        "# !wget https://raw.githubusercontent.com/maxiaoba/GRAPE/master/uci/raw_data/concrete/data/data.txt\n",
        "!wget https://raw.githubusercontent.com/sanujsriv/datasets/main/reuters_data_labels.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FreWUzP7H6Z0"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-geometric\n",
        "!pip install fancyimpute -U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dytMlqnVIAfb"
      },
      "source": [
        "# import torch\n",
        "# import torch_sparse\n",
        "# torch.version.cuda,torch.__version__,torch_sparse.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-L3T28M3nVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5b457c-49a6-479b-bae6-f1807cb1d57e"
      },
      "source": [
        "!unzip ./reuters_data_labels.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./reuters_data_labels.zip\n",
            "  inflating: retuers_data.pkl        \n",
            "  inflating: retuers_labels.pkl      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EivGqJ7vBoAo",
        "cellView": "form"
      },
      "source": [
        "#@title function : load / save pickle_obj\n",
        "import pickle\n",
        "\n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xXR8MzY7Dj7"
      },
      "source": [
        "# Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlNM9G7ElVpZ"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from torch_geometric.data import Data\n",
        "import os.path as osp\n",
        "import inspect\n",
        "import sys\n",
        "import os\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "import torch.optim as opt\n",
        "from torch.nn import Parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YLlrvdqlEsM"
      },
      "source": [
        "def save_mask(length,true_rate,log_dir,seed):\n",
        "    np.random.seed(seed)\n",
        "    mask = np.random.rand(length) < true_rate\n",
        "    np.save(osp.join(log_dir,'len'+str(length)+'rate'+str(true_rate)+'seed'+str(seed)),mask)\n",
        "    return mask\n",
        "\n",
        "def mask_edge(edge_index,edge_attr,mask,remove_edge):\n",
        "    edge_index = edge_index.clone().detach()\n",
        "    edge_attr = edge_attr.clone().detach()\n",
        "    if remove_edge:\n",
        "        edge_index = edge_index[:,mask]\n",
        "        edge_attr = edge_attr[mask]\n",
        "    else:\n",
        "        edge_attr[~mask] = 0.\n",
        "    return edge_index, edge_attr\n",
        "    \n",
        "def get_known_mask(known_prob, edge_num):\n",
        "    known_mask = (torch.FloatTensor(edge_num, 1).uniform_() < known_prob).view(-1)\n",
        "    return known_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-yJMj3UlivC"
      },
      "source": [
        "def create_node(df): # # onehot feature node, sampling of single node\n",
        "        nrow, ncol = df.shape\n",
        "        feature_ind = np.array(range(ncol))\n",
        "        feature_node = np.zeros((ncol,ncol))\n",
        "        feature_node[np.arange(ncol), feature_ind] = 1\n",
        "        sample_node = [[1]*ncol for i in range(nrow)]\n",
        "        node = sample_node + feature_node.tolist()\n",
        "        return node\n",
        "\n",
        "def create_edge_attr(df):\n",
        "    nrow, ncol = df.shape\n",
        "    edge_attr = []\n",
        "    for i in range(nrow):\n",
        "        for j in range(ncol):\n",
        "            edge_attr.append([float(df.iloc[i,j])])\n",
        "    edge_attr = edge_attr + edge_attr\n",
        "    return edge_attr\n",
        "\n",
        "def create_edge(df):\n",
        "    n_row, n_col = df.shape\n",
        "    edge_start = []\n",
        "    edge_end = []\n",
        "    for x in range(n_row):\n",
        "        edge_start = edge_start + [x] * n_col # obj\n",
        "        edge_end = edge_end + list(n_row+np.arange(n_col)) # att\n",
        "        if(x==n_row-1):\n",
        "          print(edge_start)    \n",
        "    edge_start_new = edge_start + edge_end\n",
        "    edge_end_new = edge_end + edge_start\n",
        "    return (edge_start_new, edge_end_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz8ASIRDlN8k"
      },
      "source": [
        "def get_data(df_X, df_y, train_edge_prob=0.7, split_sample_ratio=0., split_by='y', train_y_prob=0.7, seed=0, normalize=True):\n",
        "    \n",
        "    if len(df_y.shape)==1:\n",
        "        df_y = df_y.to_numpy()\n",
        "    elif len(df_y.shape)==2:\n",
        "        df_y = df_y[0].to_numpy()\n",
        "\n",
        "    if normalize:\n",
        "        x = df_X.values\n",
        "        min_max_scaler = preprocessing.MinMaxScaler()\n",
        "        x_scaled = min_max_scaler.fit_transform(x)\n",
        "        df_X = pd.DataFrame(x_scaled)\n",
        "        \n",
        "    edge_start, edge_end = create_edge(df_X)\n",
        "    edge_index = torch.tensor([edge_start, edge_end], dtype=int)\n",
        "    edge_attr = torch.tensor(create_edge_attr(df_X), dtype=torch.float)\n",
        "    node_init = create_node(df_X) \n",
        "\n",
        "    x = torch.tensor(node_init, dtype=torch.float)\n",
        "    y = torch.tensor(df_y, dtype=torch.float)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    train_edge_mask = get_known_mask(train_edge_prob, int(edge_attr.shape[0]/2))\n",
        "    double_train_edge_mask = torch.cat((train_edge_mask, train_edge_mask), dim=0)\n",
        "\n",
        "    #mask edges based on the generated train_edge_mask\n",
        "    #train_edge_index is known, test_edge_index in unknwon, i.e. missing\n",
        "    train_edge_index, train_edge_attr = mask_edge(edge_index, edge_attr,\n",
        "                                                double_train_edge_mask, True)\n",
        "    train_labels = train_edge_attr[:int(train_edge_attr.shape[0]/2),0]\n",
        "    test_edge_index, test_edge_attr = mask_edge(edge_index, edge_attr,\n",
        "                                                ~double_train_edge_mask, True)\n",
        "    test_labels = test_edge_attr[:int(test_edge_attr.shape[0]/2),0]\n",
        "    #mask the y-values during training, i.e. how we split the training and test sets\n",
        "    train_y_mask = get_known_mask(train_y_prob, y.shape[0])\n",
        "    test_y_mask = ~train_y_mask\n",
        "\n",
        "    data = Data(x=x, y=y, edge_index=edge_index, edge_attr=edge_attr,\n",
        "            train_y_mask=train_y_mask, test_y_mask=test_y_mask,\n",
        "            train_edge_index=train_edge_index,train_edge_attr=train_edge_attr,\n",
        "            train_edge_mask=train_edge_mask,train_labels=train_labels,\n",
        "            test_edge_index=test_edge_index,test_edge_attr=test_edge_attr,\n",
        "            test_edge_mask=~train_edge_mask,test_labels=test_labels, \n",
        "            df_X=df_X,df_y=df_y,\n",
        "            edge_attr_dim=train_edge_attr.shape[-1],\n",
        "            user_num=df_X.shape[0]\n",
        "            )\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ9jT-QYln9P"
      },
      "source": [
        "def get_df(name):\n",
        "  name = name.lower()\n",
        "  if (name == 'concrete'):\n",
        "    path = osp.dirname(osp.abspath(inspect.getfile(inspect.currentframe())))\n",
        "    df_np = np.loadtxt(path+'/data.txt') # concrete UCI data\n",
        "    df_concrete = pd.DataFrame(df_np,columns=['Cement','Blast Furnace Slag','Fly Ash ','Water','Superplasticizer','Coarse Aggregate ','Fine Aggregate ','Age','Concrete compressive strength'])\n",
        "    return df_concrete\n",
        "  elif (name == 'cora'): \n",
        "    feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
        "    column_names =  feature_names + [\"subject\"]\n",
        "    node_data = pd.read_csv(os.path.join('/content/cora', \"cora.content\"), sep='\\t', header=None, names=column_names)\n",
        "    edgelist = pd.read_csv(os.path.join('/content/cora', \"cora.cites\"), sep='\\t', header=None, names=[\"target\", \"source\"])\n",
        "    edgelist[\"label\"] = \"cites\"\n",
        "    return node_data\n",
        "  elif (name == 'citeseer'): \n",
        "    feature_names = [\"w_{}\".format(ii) for ii in range(3703)]\n",
        "    column_names =  feature_names + [\"subject\"]\n",
        "    node_data = pd.read_csv(os.path.join('/content/citeseer', \"citeseer.content\"), sep='\\t', header=None, names=column_names)\n",
        "    edgelist = pd.read_csv(os.path.join('/content/citeseer', \"citeseer.cites\"), sep='\\t', header=None, names=[\"target\", \"source\"])\n",
        "    edgelist[\"label\"] = \"cites\"\n",
        "    return node_data\n",
        "  elif (name == 'reuters'):\n",
        "    data_preprocessed = load_obj('retuers_data')\n",
        "    data_preprocessed_labels = load_obj('retuers_labels')\n",
        "    preprossed_data = data_preprocessed\n",
        "    train_label = data_preprocessed_labels\n",
        "    vectorizer = CountVectorizer(min_df=0.01,max_df=0.4)\n",
        "    train_vec = vectorizer.fit_transform(preprossed_data).toarray()\n",
        "    vocab = vectorizer.vocabulary_\n",
        "    id_vocab = dict(map(reversed, vocab.items()))\n",
        "    nonzeros_indexes = np.where(train_vec.any(1))[0]\n",
        "    train_vec_non_zeros = [train_vec[i] for i in nonzeros_indexes]\n",
        "    preprossed_data_non_zeros = [preprossed_data[i] for i in nonzeros_indexes]\n",
        "    train_label = [data_preprocessed_labels[i] for i in nonzeros_indexes]\n",
        "    train_vec = np.asanyarray(train_vec_non_zeros)\n",
        "    sorted_id_word_vocab = sorted(id_vocab.items(), key=lambda x: x[1]) ### alphabetically sorted\n",
        "    word_list = [s[1] for s in sorted_id_word_vocab]\n",
        "    df = pd.DataFrame(train_vec,columns=word_list)\n",
        "    df['label']=train_label\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "zbGxtqMvedZe",
        "outputId": "8bb2949e-bda0-4ead-be38-2dba46cecfe0"
      },
      "source": [
        "df_data = 'citeseer'\n",
        "df = get_df(df_data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['w_0', 'w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6', 'w_7', 'w_8', 'w_9', 'w_10', 'w_11', 'w_12', 'w_13', 'w_14', 'w_15', 'w_16', 'w_17', 'w_18', 'w_19', 'w_20', 'w_21', 'w_22', 'w_23', 'w_24', 'w_25', 'w_26', 'w_27', 'w_28', 'w_29', 'w_30', 'w_31', 'w_32', 'w_33', 'w_34', 'w_35', 'w_36', 'w_37', 'w_38', 'w_39', 'w_40', 'w_41', 'w_42', 'w_43', 'w_44', 'w_45', 'w_46', 'w_47', 'w_48', 'w_49', 'w_50', 'w_51', 'w_52', 'w_53', 'w_54', 'w_55', 'w_56', 'w_57', 'w_58', 'w_59', 'w_60', 'w_61', 'w_62', 'w_63', 'w_64', 'w_65', 'w_66', 'w_67', 'w_68', 'w_69', 'w_70', 'w_71', 'w_72', 'w_73', 'w_74', 'w_75', 'w_76', 'w_77', 'w_78', 'w_79', 'w_80', 'w_81', 'w_82', 'w_83', 'w_84', 'w_85', 'w_86', 'w_87', 'w_88', 'w_89', 'w_90', 'w_91', 'w_92', 'w_93', 'w_94', 'w_95', 'w_96', 'w_97', 'w_98', 'w_99', 'w_100', 'w_101', 'w_102', 'w_103', 'w_104', 'w_105', 'w_106', 'w_107', 'w_108', 'w_109', 'w_110', 'w_111', 'w_112', 'w_113', 'w_114', 'w_115', 'w_116', 'w_117', 'w_118', 'w_119', 'w_120', 'w_121', 'w_122', 'w_123', 'w_124', 'w_125', 'w_126', 'w_127', 'w_128', 'w_129', 'w_130', 'w_131', 'w_132', 'w_133', 'w_134', 'w_135', 'w_136', 'w_137', 'w_138', 'w_139', 'w_140', 'w_141', 'w_142', 'w_143', 'w_144', 'w_145', 'w_146', 'w_147', 'w_148', 'w_149', 'w_150', 'w_151', 'w_152', 'w_153', 'w_154', 'w_155', 'w_156', 'w_157', 'w_158', 'w_159', 'w_160', 'w_161', 'w_162', 'w_163', 'w_164', 'w_165', 'w_166', 'w_167', 'w_168', 'w_169', 'w_170', 'w_171', 'w_172', 'w_173', 'w_174', 'w_175', 'w_176', 'w_177', 'w_178', 'w_179', 'w_180', 'w_181', 'w_182', 'w_183', 'w_184', 'w_185', 'w_186', 'w_187', 'w_188', 'w_189', 'w_190', 'w_191', 'w_192', 'w_193', 'w_194', 'w_195', 'w_196', 'w_197', 'w_198', 'w_199', 'w_200', 'w_201', 'w_202', 'w_203', 'w_204', 'w_205', 'w_206', 'w_207', 'w_208', 'w_209', 'w_210', 'w_211', 'w_212', 'w_213', 'w_214', 'w_215', 'w_216', 'w_217', 'w_218', 'w_219', 'w_220', 'w_221', 'w_222', 'w_223', 'w_224', 'w_225', 'w_226', 'w_227', 'w_228', 'w_229', 'w_230', 'w_231', 'w_232', 'w_233', 'w_234', 'w_235', 'w_236', 'w_237', 'w_238', 'w_239', 'w_240', 'w_241', 'w_242', 'w_243', 'w_244', 'w_245', 'w_246', 'w_247', 'w_248', 'w_249', 'w_250', 'w_251', 'w_252', 'w_253', 'w_254', 'w_255', 'w_256', 'w_257', 'w_258', 'w_259', 'w_260', 'w_261', 'w_262', 'w_263', 'w_264', 'w_265', 'w_266', 'w_267', 'w_268', 'w_269', 'w_270', 'w_271', 'w_272', 'w_273', 'w_274', 'w_275', 'w_276', 'w_277', 'w_278', 'w_279', 'w_280', 'w_281', 'w_282', 'w_283', 'w_284', 'w_285', 'w_286', 'w_287', 'w_288', 'w_289', 'w_290', 'w_291', 'w_292', 'w_293', 'w_294', 'w_295', 'w_296', 'w_297', 'w_298', 'w_299', 'w_300', 'w_301', 'w_302', 'w_303', 'w_304', 'w_305', 'w_306', 'w_307', 'w_308', 'w_309', 'w_310', 'w_311', 'w_312', 'w_313', 'w_314', 'w_315', 'w_316', 'w_317', 'w_318', 'w_319', 'w_320', 'w_321', 'w_322', 'w_323', 'w_324', 'w_325', 'w_326', 'w_327', 'w_328', 'w_329', 'w_330', 'w_331', 'w_332', 'w_333', 'w_334', 'w_335', 'w_336', 'w_337', 'w_338', 'w_339', 'w_340', 'w_341', 'w_342', 'w_343', 'w_344', 'w_345', 'w_346', 'w_347', 'w_348', 'w_349', 'w_350', 'w_351', 'w_352', 'w_353', 'w_354', 'w_355', 'w_356', 'w_357', 'w_358', 'w_359', 'w_360', 'w_361', 'w_362', 'w_363', 'w_364', 'w_365', 'w_366', 'w_367', 'w_368', 'w_369', 'w_370', 'w_371', 'w_372', 'w_373', 'w_374', 'w_375', 'w_376', 'w_377', 'w_378', 'w_379', 'w_380', 'w_381', 'w_382', 'w_383', 'w_384', 'w_385', 'w_386', 'w_387', 'w_388', 'w_389', 'w_390', 'w_391', 'w_392', 'w_393', 'w_394', 'w_395', 'w_396', 'w_397', 'w_398', 'w_399', 'w_400', 'w_401', 'w_402', 'w_403', 'w_404', 'w_405', 'w_406', 'w_407', 'w_408', 'w_409', 'w_410', 'w_411', 'w_412', 'w_413', 'w_414', 'w_415', 'w_416', 'w_417', 'w_418', 'w_419', 'w_420', 'w_421', 'w_422', 'w_423', 'w_424', 'w_425', 'w_426', 'w_427', 'w_428', 'w_429', 'w_430', 'w_431', 'w_432', 'w_433', 'w_434', 'w_435', 'w_436', 'w_437', 'w_438', 'w_439', 'w_440', 'w_441', 'w_442', 'w_443', 'w_444', 'w_445', 'w_446', 'w_447', 'w_448', 'w_449', 'w_450', 'w_451', 'w_452', 'w_453', 'w_454', 'w_455', 'w_456', 'w_457', 'w_458', 'w_459', 'w_460', 'w_461', 'w_462', 'w_463', 'w_464', 'w_465', 'w_466', 'w_467', 'w_468', 'w_469', 'w_470', 'w_471', 'w_472', 'w_473', 'w_474', 'w_475', 'w_476', 'w_477', 'w_478', 'w_479', 'w_480', 'w_481', 'w_482', 'w_483', 'w_484', 'w_485', 'w_486', 'w_487', 'w_488', 'w_489', 'w_490', 'w_491', 'w_492', 'w_493', 'w_494', 'w_495', 'w_496', 'w_497', 'w_498', 'w_499', 'w_500', 'w_501', 'w_502', 'w_503', 'w_504', 'w_505', 'w_506', 'w_507', 'w_508', 'w_509', 'w_510', 'w_511', 'w_512', 'w_513', 'w_514', 'w_515', 'w_516', 'w_517', 'w_518', 'w_519', 'w_520', 'w_521', 'w_522', 'w_523', 'w_524', 'w_525', 'w_526', 'w_527', 'w_528', 'w_529', 'w_530', 'w_531', 'w_532', 'w_533', 'w_534', 'w_535', 'w_536', 'w_537', 'w_538', 'w_539', 'w_540', 'w_541', 'w_542', 'w_543', 'w_544', 'w_545', 'w_546', 'w_547', 'w_548', 'w_549', 'w_550', 'w_551', 'w_552', 'w_553', 'w_554', 'w_555', 'w_556', 'w_557', 'w_558', 'w_559', 'w_560', 'w_561', 'w_562', 'w_563', 'w_564', 'w_565', 'w_566', 'w_567', 'w_568', 'w_569', 'w_570', 'w_571', 'w_572', 'w_573', 'w_574', 'w_575', 'w_576', 'w_577', 'w_578', 'w_579', 'w_580', 'w_581', 'w_582', 'w_583', 'w_584', 'w_585', 'w_586', 'w_587', 'w_588', 'w_589', 'w_590', 'w_591', 'w_592', 'w_593', 'w_594', 'w_595', 'w_596', 'w_597', 'w_598', 'w_599', 'w_600', 'w_601', 'w_602', 'w_603', 'w_604', 'w_605', 'w_606', 'w_607', 'w_608', 'w_609', 'w_610', 'w_611', 'w_612', 'w_613', 'w_614', 'w_615', 'w_616', 'w_617', 'w_618', 'w_619', 'w_620', 'w_621', 'w_622', 'w_623', 'w_624', 'w_625', 'w_626', 'w_627', 'w_628', 'w_629', 'w_630', 'w_631', 'w_632', 'w_633', 'w_634', 'w_635', 'w_636', 'w_637', 'w_638', 'w_639', 'w_640', 'w_641', 'w_642', 'w_643', 'w_644', 'w_645', 'w_646', 'w_647', 'w_648', 'w_649', 'w_650', 'w_651', 'w_652', 'w_653', 'w_654', 'w_655', 'w_656', 'w_657', 'w_658', 'w_659', 'w_660', 'w_661', 'w_662', 'w_663', 'w_664', 'w_665', 'w_666', 'w_667', 'w_668', 'w_669', 'w_670', 'w_671', 'w_672', 'w_673', 'w_674', 'w_675', 'w_676', 'w_677', 'w_678', 'w_679', 'w_680', 'w_681', 'w_682', 'w_683', 'w_684', 'w_685', 'w_686', 'w_687', 'w_688', 'w_689', 'w_690', 'w_691', 'w_692', 'w_693', 'w_694', 'w_695', 'w_696', 'w_697', 'w_698', 'w_699', 'w_700', 'w_701', 'w_702', 'w_703', 'w_704', 'w_705', 'w_706', 'w_707', 'w_708', 'w_709', 'w_710', 'w_711', 'w_712', 'w_713', 'w_714', 'w_715', 'w_716', 'w_717', 'w_718', 'w_719', 'w_720', 'w_721', 'w_722', 'w_723', 'w_724', 'w_725', 'w_726', 'w_727', 'w_728', 'w_729', 'w_730', 'w_731', 'w_732', 'w_733', 'w_734', 'w_735', 'w_736', 'w_737', 'w_738', 'w_739', 'w_740', 'w_741', 'w_742', 'w_743', 'w_744', 'w_745', 'w_746', 'w_747', 'w_748', 'w_749', 'w_750', 'w_751', 'w_752', 'w_753', 'w_754', 'w_755', 'w_756', 'w_757', 'w_758', 'w_759', 'w_760', 'w_761', 'w_762', 'w_763', 'w_764', 'w_765', 'w_766', 'w_767', 'w_768', 'w_769', 'w_770', 'w_771', 'w_772', 'w_773', 'w_774', 'w_775', 'w_776', 'w_777', 'w_778', 'w_779', 'w_780', 'w_781', 'w_782', 'w_783', 'w_784', 'w_785', 'w_786', 'w_787', 'w_788', 'w_789', 'w_790', 'w_791', 'w_792', 'w_793', 'w_794', 'w_795', 'w_796', 'w_797', 'w_798', 'w_799', 'w_800', 'w_801', 'w_802', 'w_803', 'w_804', 'w_805', 'w_806', 'w_807', 'w_808', 'w_809', 'w_810', 'w_811', 'w_812', 'w_813', 'w_814', 'w_815', 'w_816', 'w_817', 'w_818', 'w_819', 'w_820', 'w_821', 'w_822', 'w_823', 'w_824', 'w_825', 'w_826', 'w_827', 'w_828', 'w_829', 'w_830', 'w_831', 'w_832', 'w_833', 'w_834', 'w_835', 'w_836', 'w_837', 'w_838', 'w_839', 'w_840', 'w_841', 'w_842', 'w_843', 'w_844', 'w_845', 'w_846', 'w_847', 'w_848', 'w_849', 'w_850', 'w_851', 'w_852', 'w_853', 'w_854', 'w_855', 'w_856', 'w_857', 'w_858', 'w_859', 'w_860', 'w_861', 'w_862', 'w_863', 'w_864', 'w_865', 'w_866', 'w_867', 'w_868', 'w_869', 'w_870', 'w_871', 'w_872', 'w_873', 'w_874', 'w_875', 'w_876', 'w_877', 'w_878', 'w_879', 'w_880', 'w_881', 'w_882', 'w_883', 'w_884', 'w_885', 'w_886', 'w_887', 'w_888', 'w_889', 'w_890', 'w_891', 'w_892', 'w_893', 'w_894', 'w_895', 'w_896', 'w_897', 'w_898', 'w_899', 'w_900', 'w_901', 'w_902', 'w_903', 'w_904', 'w_905', 'w_906', 'w_907', 'w_908', 'w_909', 'w_910', 'w_911', 'w_912', 'w_913', 'w_914', 'w_915', 'w_916', 'w_917', 'w_918', 'w_919', 'w_920', 'w_921', 'w_922', 'w_923', 'w_924', 'w_925', 'w_926', 'w_927', 'w_928', 'w_929', 'w_930', 'w_931', 'w_932', 'w_933', 'w_934', 'w_935', 'w_936', 'w_937', 'w_938', 'w_939', 'w_940', 'w_941', 'w_942', 'w_943', 'w_944', 'w_945', 'w_946', 'w_947', 'w_948', 'w_949', 'w_950', 'w_951', 'w_952', 'w_953', 'w_954', 'w_955', 'w_956', 'w_957', 'w_958', 'w_959', 'w_960', 'w_961', 'w_962', 'w_963', 'w_964', 'w_965', 'w_966', 'w_967', 'w_968', 'w_969', 'w_970', 'w_971', 'w_972', 'w_973', 'w_974', 'w_975', 'w_976', 'w_977', 'w_978', 'w_979', 'w_980', 'w_981', 'w_982', 'w_983', 'w_984', 'w_985', 'w_986', 'w_987', 'w_988', 'w_989', 'w_990', 'w_991', 'w_992', 'w_993', 'w_994', 'w_995', 'w_996', 'w_997', 'w_998', 'w_999', 'w_1000', 'w_1001', 'w_1002', 'w_1003', 'w_1004', 'w_1005', 'w_1006', 'w_1007', 'w_1008', 'w_1009', 'w_1010', 'w_1011', 'w_1012', 'w_1013', 'w_1014', 'w_1015', 'w_1016', 'w_1017', 'w_1018', 'w_1019', 'w_1020', 'w_1021', 'w_1022', 'w_1023', 'w_1024', 'w_1025', 'w_1026', 'w_1027', 'w_1028', 'w_1029', 'w_1030', 'w_1031', 'w_1032', 'w_1033', 'w_1034', 'w_1035', 'w_1036', 'w_1037', 'w_1038', 'w_1039', 'w_1040', 'w_1041', 'w_1042', 'w_1043', 'w_1044', 'w_1045', 'w_1046', 'w_1047', 'w_1048', 'w_1049', 'w_1050', 'w_1051', 'w_1052', 'w_1053', 'w_1054', 'w_1055', 'w_1056', 'w_1057', 'w_1058', 'w_1059', 'w_1060', 'w_1061', 'w_1062', 'w_1063', 'w_1064', 'w_1065', 'w_1066', 'w_1067', 'w_1068', 'w_1069', 'w_1070', 'w_1071', 'w_1072', 'w_1073', 'w_1074', 'w_1075', 'w_1076', 'w_1077', 'w_1078', 'w_1079', 'w_1080', 'w_1081', 'w_1082', 'w_1083', 'w_1084', 'w_1085', 'w_1086', 'w_1087', 'w_1088', 'w_1089', 'w_1090', 'w_1091', 'w_1092', 'w_1093', 'w_1094', 'w_1095', 'w_1096', 'w_1097', 'w_1098', 'w_1099', 'w_1100', 'w_1101', 'w_1102', 'w_1103', 'w_1104', 'w_1105', 'w_1106', 'w_1107', 'w_1108', 'w_1109', 'w_1110', 'w_1111', 'w_1112', 'w_1113', 'w_1114', 'w_1115', 'w_1116', 'w_1117', 'w_1118', 'w_1119', 'w_1120', 'w_1121', 'w_1122', 'w_1123', 'w_1124', 'w_1125', 'w_1126', 'w_1127', 'w_1128', 'w_1129', 'w_1130', 'w_1131', 'w_1132', 'w_1133', 'w_1134', 'w_1135', 'w_1136', 'w_1137', 'w_1138', 'w_1139', 'w_1140', 'w_1141', 'w_1142', 'w_1143', 'w_1144', 'w_1145', 'w_1146', 'w_1147', 'w_1148', 'w_1149', 'w_1150', 'w_1151', 'w_1152', 'w_1153', 'w_1154', 'w_1155', 'w_1156', 'w_1157', 'w_1158', 'w_1159', 'w_1160', 'w_1161', 'w_1162', 'w_1163', 'w_1164', 'w_1165', 'w_1166', 'w_1167', 'w_1168', 'w_1169', 'w_1170', 'w_1171', 'w_1172', 'w_1173', 'w_1174', 'w_1175', 'w_1176', 'w_1177', 'w_1178', 'w_1179', 'w_1180', 'w_1181', 'w_1182', 'w_1183', 'w_1184', 'w_1185', 'w_1186', 'w_1187', 'w_1188', 'w_1189', 'w_1190', 'w_1191', 'w_1192', 'w_1193', 'w_1194', 'w_1195', 'w_1196', 'w_1197', 'w_1198', 'w_1199', 'w_1200', 'w_1201', 'w_1202', 'w_1203', 'w_1204', 'w_1205', 'w_1206', 'w_1207', 'w_1208', 'w_1209', 'w_1210', 'w_1211', 'w_1212', 'w_1213', 'w_1214', 'w_1215', 'w_1216', 'w_1217', 'w_1218', 'w_1219', 'w_1220', 'w_1221', 'w_1222', 'w_1223', 'w_1224', 'w_1225', 'w_1226', 'w_1227', 'w_1228', 'w_1229', 'w_1230', 'w_1231', 'w_1232', 'w_1233', 'w_1234', 'w_1235', 'w_1236', 'w_1237', 'w_1238', 'w_1239', 'w_1240', 'w_1241', 'w_1242', 'w_1243', 'w_1244', 'w_1245', 'w_1246', 'w_1247', 'w_1248', 'w_1249', 'w_1250', 'w_1251', 'w_1252', 'w_1253', 'w_1254', 'w_1255', 'w_1256', 'w_1257', 'w_1258', 'w_1259', 'w_1260', 'w_1261', 'w_1262', 'w_1263', 'w_1264', 'w_1265', 'w_1266', 'w_1267', 'w_1268', 'w_1269', 'w_1270', 'w_1271', 'w_1272', 'w_1273', 'w_1274', 'w_1275', 'w_1276', 'w_1277', 'w_1278', 'w_1279', 'w_1280', 'w_1281', 'w_1282', 'w_1283', 'w_1284', 'w_1285', 'w_1286', 'w_1287', 'w_1288', 'w_1289', 'w_1290', 'w_1291', 'w_1292', 'w_1293', 'w_1294', 'w_1295', 'w_1296', 'w_1297', 'w_1298', 'w_1299', 'w_1300', 'w_1301', 'w_1302', 'w_1303', 'w_1304', 'w_1305', 'w_1306', 'w_1307', 'w_1308', 'w_1309', 'w_1310', 'w_1311', 'w_1312', 'w_1313', 'w_1314', 'w_1315', 'w_1316', 'w_1317', 'w_1318', 'w_1319', 'w_1320', 'w_1321', 'w_1322', 'w_1323', 'w_1324', 'w_1325', 'w_1326', 'w_1327', 'w_1328', 'w_1329', 'w_1330', 'w_1331', 'w_1332', 'w_1333', 'w_1334', 'w_1335', 'w_1336', 'w_1337', 'w_1338', 'w_1339', 'w_1340', 'w_1341', 'w_1342', 'w_1343', 'w_1344', 'w_1345', 'w_1346', 'w_1347', 'w_1348', 'w_1349', 'w_1350', 'w_1351', 'w_1352', 'w_1353', 'w_1354', 'w_1355', 'w_1356', 'w_1357', 'w_1358', 'w_1359', 'w_1360', 'w_1361', 'w_1362', 'w_1363', 'w_1364', 'w_1365', 'w_1366', 'w_1367', 'w_1368', 'w_1369', 'w_1370', 'w_1371', 'w_1372', 'w_1373', 'w_1374', 'w_1375', 'w_1376', 'w_1377', 'w_1378', 'w_1379', 'w_1380', 'w_1381', 'w_1382', 'w_1383', 'w_1384', 'w_1385', 'w_1386', 'w_1387', 'w_1388', 'w_1389', 'w_1390', 'w_1391', 'w_1392', 'w_1393', 'w_1394', 'w_1395', 'w_1396', 'w_1397', 'w_1398', 'w_1399', 'w_1400', 'w_1401', 'w_1402', 'w_1403', 'w_1404', 'w_1405', 'w_1406', 'w_1407', 'w_1408', 'w_1409', 'w_1410', 'w_1411', 'w_1412', 'w_1413', 'w_1414', 'w_1415', 'w_1416', 'w_1417', 'w_1418', 'w_1419', 'w_1420', 'w_1421', 'w_1422', 'w_1423', 'w_1424', 'w_1425', 'w_1426', 'w_1427', 'w_1428', 'w_1429', 'w_1430', 'w_1431', 'w_1432', 'w_1433', 'w_1434', 'w_1435', 'w_1436', 'w_1437', 'w_1438', 'w_1439', 'w_1440', 'w_1441', 'w_1442', 'w_1443', 'w_1444', 'w_1445', 'w_1446', 'w_1447', 'w_1448', 'w_1449', 'w_1450', 'w_1451', 'w_1452', 'w_1453', 'w_1454', 'w_1455', 'w_1456', 'w_1457', 'w_1458', 'w_1459', 'w_1460', 'w_1461', 'w_1462', 'w_1463', 'w_1464', 'w_1465', 'w_1466', 'w_1467', 'w_1468', 'w_1469', 'w_1470', 'w_1471', 'w_1472', 'w_1473', 'w_1474', 'w_1475', 'w_1476', 'w_1477', 'w_1478', 'w_1479', 'w_1480', 'w_1481', 'w_1482', 'w_1483', 'w_1484', 'w_1485', 'w_1486', 'w_1487', 'w_1488', 'w_1489', 'w_1490', 'w_1491', 'w_1492', 'w_1493', 'w_1494', 'w_1495', 'w_1496', 'w_1497', 'w_1498', 'w_1499', 'w_1500', 'w_1501', 'w_1502', 'w_1503', 'w_1504', 'w_1505', 'w_1506', 'w_1507', 'w_1508', 'w_1509', 'w_1510', 'w_1511', 'w_1512', 'w_1513', 'w_1514', 'w_1515', 'w_1516', 'w_1517', 'w_1518', 'w_1519', 'w_1520', 'w_1521', 'w_1522', 'w_1523', 'w_1524', 'w_1525', 'w_1526', 'w_1527', 'w_1528', 'w_1529', 'w_1530', 'w_1531', 'w_1532', 'w_1533', 'w_1534', 'w_1535', 'w_1536', 'w_1537', 'w_1538', 'w_1539', 'w_1540', 'w_1541', 'w_1542', 'w_1543', 'w_1544', 'w_1545', 'w_1546', 'w_1547', 'w_1548', 'w_1549', 'w_1550', 'w_1551', 'w_1552', 'w_1553', 'w_1554', 'w_1555', 'w_1556', 'w_1557', 'w_1558', 'w_1559', 'w_1560', 'w_1561', 'w_1562', 'w_1563', 'w_1564', 'w_1565', 'w_1566', 'w_1567', 'w_1568', 'w_1569', 'w_1570', 'w_1571', 'w_1572', 'w_1573', 'w_1574', 'w_1575', 'w_1576', 'w_1577', 'w_1578', 'w_1579', 'w_1580', 'w_1581', 'w_1582', 'w_1583', 'w_1584', 'w_1585', 'w_1586', 'w_1587', 'w_1588', 'w_1589', 'w_1590', 'w_1591', 'w_1592', 'w_1593', 'w_1594', 'w_1595', 'w_1596', 'w_1597', 'w_1598', 'w_1599', 'w_1600', 'w_1601', 'w_1602', 'w_1603', 'w_1604', 'w_1605', 'w_1606', 'w_1607', 'w_1608', 'w_1609', 'w_1610', 'w_1611', 'w_1612', 'w_1613', 'w_1614', 'w_1615', 'w_1616', 'w_1617', 'w_1618', 'w_1619', 'w_1620', 'w_1621', 'w_1622', 'w_1623', 'w_1624', 'w_1625', 'w_1626', 'w_1627', 'w_1628', 'w_1629', 'w_1630', 'w_1631', 'w_1632', 'w_1633', 'w_1634', 'w_1635', 'w_1636', 'w_1637', 'w_1638', 'w_1639', 'w_1640', 'w_1641', 'w_1642', 'w_1643', 'w_1644', 'w_1645', 'w_1646', 'w_1647', 'w_1648', 'w_1649', 'w_1650', 'w_1651', 'w_1652', 'w_1653', 'w_1654', 'w_1655', 'w_1656', 'w_1657', 'w_1658', 'w_1659', 'w_1660', 'w_1661', 'w_1662', 'w_1663', 'w_1664', 'w_1665', 'w_1666', 'w_1667', 'w_1668', 'w_1669', 'w_1670', 'w_1671', 'w_1672', 'w_1673', 'w_1674', 'w_1675', 'w_1676', 'w_1677', 'w_1678', 'w_1679', 'w_1680', 'w_1681', 'w_1682', 'w_1683', 'w_1684', 'w_1685', 'w_1686', 'w_1687', 'w_1688', 'w_1689', 'w_1690', 'w_1691', 'w_1692', 'w_1693', 'w_1694', 'w_1695', 'w_1696', 'w_1697', 'w_1698', 'w_1699', 'w_1700', 'w_1701', 'w_1702', 'w_1703', 'w_1704', 'w_1705', 'w_1706', 'w_1707', 'w_1708', 'w_1709', 'w_1710', 'w_1711', 'w_1712', 'w_1713', 'w_1714', 'w_1715', 'w_1716', 'w_1717', 'w_1718', 'w_1719', 'w_1720', 'w_1721', 'w_1722', 'w_1723', 'w_1724', 'w_1725', 'w_1726', 'w_1727', 'w_1728', 'w_1729', 'w_1730', 'w_1731', 'w_1732', 'w_1733', 'w_1734', 'w_1735', 'w_1736', 'w_1737', 'w_1738', 'w_1739', 'w_1740', 'w_1741', 'w_1742', 'w_1743', 'w_1744', 'w_1745', 'w_1746', 'w_1747', 'w_1748', 'w_1749', 'w_1750', 'w_1751', 'w_1752', 'w_1753', 'w_1754', 'w_1755', 'w_1756', 'w_1757', 'w_1758', 'w_1759', 'w_1760', 'w_1761', 'w_1762', 'w_1763', 'w_1764', 'w_1765', 'w_1766', 'w_1767', 'w_1768', 'w_1769', 'w_1770', 'w_1771', 'w_1772', 'w_1773', 'w_1774', 'w_1775', 'w_1776', 'w_1777', 'w_1778', 'w_1779', 'w_1780', 'w_1781', 'w_1782', 'w_1783', 'w_1784', 'w_1785', 'w_1786', 'w_1787', 'w_1788', 'w_1789', 'w_1790', 'w_1791', 'w_1792', 'w_1793', 'w_1794', 'w_1795', 'w_1796', 'w_1797', 'w_1798', 'w_1799', 'w_1800', 'w_1801', 'w_1802', 'w_1803', 'w_1804', 'w_1805', 'w_1806', 'w_1807', 'w_1808', 'w_1809', 'w_1810', 'w_1811', 'w_1812', 'w_1813', 'w_1814', 'w_1815', 'w_1816', 'w_1817', 'w_1818', 'w_1819', 'w_1820', 'w_1821', 'w_1822', 'w_1823', 'w_1824', 'w_1825', 'w_1826', 'w_1827', 'w_1828', 'w_1829', 'w_1830', 'w_1831', 'w_1832', 'w_1833', 'w_1834', 'w_1835', 'w_1836', 'w_1837', 'w_1838', 'w_1839', 'w_1840', 'w_1841', 'w_1842', 'w_1843', 'w_1844', 'w_1845', 'w_1846', 'w_1847', 'w_1848', 'w_1849', 'w_1850', 'w_1851', 'w_1852', 'w_1853', 'w_1854', 'w_1855', 'w_1856', 'w_1857', 'w_1858', 'w_1859', 'w_1860', 'w_1861', 'w_1862', 'w_1863', 'w_1864', 'w_1865', 'w_1866', 'w_1867', 'w_1868', 'w_1869', 'w_1870', 'w_1871', 'w_1872', 'w_1873', 'w_1874', 'w_1875', 'w_1876', 'w_1877', 'w_1878', 'w_1879', 'w_1880', 'w_1881', 'w_1882', 'w_1883', 'w_1884', 'w_1885', 'w_1886', 'w_1887', 'w_1888', 'w_1889', 'w_1890', 'w_1891', 'w_1892', 'w_1893', 'w_1894', 'w_1895', 'w_1896', 'w_1897', 'w_1898', 'w_1899', 'w_1900', 'w_1901', 'w_1902', 'w_1903', 'w_1904', 'w_1905', 'w_1906', 'w_1907', 'w_1908', 'w_1909', 'w_1910', 'w_1911', 'w_1912', 'w_1913', 'w_1914', 'w_1915', 'w_1916', 'w_1917', 'w_1918', 'w_1919', 'w_1920', 'w_1921', 'w_1922', 'w_1923', 'w_1924', 'w_1925', 'w_1926', 'w_1927', 'w_1928', 'w_1929', 'w_1930', 'w_1931', 'w_1932', 'w_1933', 'w_1934', 'w_1935', 'w_1936', 'w_1937', 'w_1938', 'w_1939', 'w_1940', 'w_1941', 'w_1942', 'w_1943', 'w_1944', 'w_1945', 'w_1946', 'w_1947', 'w_1948', 'w_1949', 'w_1950', 'w_1951', 'w_1952', 'w_1953', 'w_1954', 'w_1955', 'w_1956', 'w_1957', 'w_1958', 'w_1959', 'w_1960', 'w_1961', 'w_1962', 'w_1963', 'w_1964', 'w_1965', 'w_1966', 'w_1967', 'w_1968', 'w_1969', 'w_1970', 'w_1971', 'w_1972', 'w_1973', 'w_1974', 'w_1975', 'w_1976', 'w_1977', 'w_1978', 'w_1979', 'w_1980', 'w_1981', 'w_1982', 'w_1983', 'w_1984', 'w_1985', 'w_1986', 'w_1987', 'w_1988', 'w_1989', 'w_1990', 'w_1991', 'w_1992', 'w_1993', 'w_1994', 'w_1995', 'w_1996', 'w_1997', 'w_1998', 'w_1999', 'w_2000', 'w_2001', 'w_2002', 'w_2003', 'w_2004', 'w_2005', 'w_2006', 'w_2007', 'w_2008', 'w_2009', 'w_2010', 'w_2011', 'w_2012', 'w_2013', 'w_2014', 'w_2015', 'w_2016', 'w_2017', 'w_2018', 'w_2019', 'w_2020', 'w_2021', 'w_2022', 'w_2023', 'w_2024', 'w_2025', 'w_2026', 'w_2027', 'w_2028', 'w_2029', 'w_2030', 'w_2031', 'w_2032', 'w_2033', 'w_2034', 'w_2035', 'w_2036', 'w_2037', 'w_2038', 'w_2039', 'w_2040', 'w_2041', 'w_2042', 'w_2043', 'w_2044', 'w_2045', 'w_2046', 'w_2047', 'w_2048', 'w_2049', 'w_2050', 'w_2051', 'w_2052', 'w_2053', 'w_2054', 'w_2055', 'w_2056', 'w_2057', 'w_2058', 'w_2059', 'w_2060', 'w_2061', 'w_2062', 'w_2063', 'w_2064', 'w_2065', 'w_2066', 'w_2067', 'w_2068', 'w_2069', 'w_2070', 'w_2071', 'w_2072', 'w_2073', 'w_2074', 'w_2075', 'w_2076', 'w_2077', 'w_2078', 'w_2079', 'w_2080', 'w_2081', 'w_2082', 'w_2083', 'w_2084', 'w_2085', 'w_2086', 'w_2087', 'w_2088', 'w_2089', 'w_2090', 'w_2091', 'w_2092', 'w_2093', 'w_2094', 'w_2095', 'w_2096', 'w_2097', 'w_2098', 'w_2099', 'w_2100', 'w_2101', 'w_2102', 'w_2103', 'w_2104', 'w_2105', 'w_2106', 'w_2107', 'w_2108', 'w_2109', 'w_2110', 'w_2111', 'w_2112', 'w_2113', 'w_2114', 'w_2115', 'w_2116', 'w_2117', 'w_2118', 'w_2119', 'w_2120', 'w_2121', 'w_2122', 'w_2123', 'w_2124', 'w_2125', 'w_2126', 'w_2127', 'w_2128', 'w_2129', 'w_2130', 'w_2131', 'w_2132', 'w_2133', 'w_2134', 'w_2135', 'w_2136', 'w_2137', 'w_2138', 'w_2139', 'w_2140', 'w_2141', 'w_2142', 'w_2143', 'w_2144', 'w_2145', 'w_2146', 'w_2147', 'w_2148', 'w_2149', 'w_2150', 'w_2151', 'w_2152', 'w_2153', 'w_2154', 'w_2155', 'w_2156', 'w_2157', 'w_2158', 'w_2159', 'w_2160', 'w_2161', 'w_2162', 'w_2163', 'w_2164', 'w_2165', 'w_2166', 'w_2167', 'w_2168', 'w_2169', 'w_2170', 'w_2171', 'w_2172', 'w_2173', 'w_2174', 'w_2175', 'w_2176', 'w_2177', 'w_2178', 'w_2179', 'w_2180', 'w_2181', 'w_2182', 'w_2183', 'w_2184', 'w_2185', 'w_2186', 'w_2187', 'w_2188', 'w_2189', 'w_2190', 'w_2191', 'w_2192', 'w_2193', 'w_2194', 'w_2195', 'w_2196', 'w_2197', 'w_2198', 'w_2199', 'w_2200', 'w_2201', 'w_2202', 'w_2203', 'w_2204', 'w_2205', 'w_2206', 'w_2207', 'w_2208', 'w_2209', 'w_2210', 'w_2211', 'w_2212', 'w_2213', 'w_2214', 'w_2215', 'w_2216', 'w_2217', 'w_2218', 'w_2219', 'w_2220', 'w_2221', 'w_2222', 'w_2223', 'w_2224', 'w_2225', 'w_2226', 'w_2227', 'w_2228', 'w_2229', 'w_2230', 'w_2231', 'w_2232', 'w_2233', 'w_2234', 'w_2235', 'w_2236', 'w_2237', 'w_2238', 'w_2239', 'w_2240', 'w_2241', 'w_2242', 'w_2243', 'w_2244', 'w_2245', 'w_2246', 'w_2247', 'w_2248', 'w_2249', 'w_2250', 'w_2251', 'w_2252', 'w_2253', 'w_2254', 'w_2255', 'w_2256', 'w_2257', 'w_2258', 'w_2259', 'w_2260', 'w_2261', 'w_2262', 'w_2263', 'w_2264', 'w_2265', 'w_2266', 'w_2267', 'w_2268', 'w_2269', 'w_2270', 'w_2271', 'w_2272', 'w_2273', 'w_2274', 'w_2275', 'w_2276', 'w_2277', 'w_2278', 'w_2279', 'w_2280', 'w_2281', 'w_2282', 'w_2283', 'w_2284', 'w_2285', 'w_2286', 'w_2287', 'w_2288', 'w_2289', 'w_2290', 'w_2291', 'w_2292', 'w_2293', 'w_2294', 'w_2295', 'w_2296', 'w_2297', 'w_2298', 'w_2299', 'w_2300', 'w_2301', 'w_2302', 'w_2303', 'w_2304', 'w_2305', 'w_2306', 'w_2307', 'w_2308', 'w_2309', 'w_2310', 'w_2311', 'w_2312', 'w_2313', 'w_2314', 'w_2315', 'w_2316', 'w_2317', 'w_2318', 'w_2319', 'w_2320', 'w_2321', 'w_2322', 'w_2323', 'w_2324', 'w_2325', 'w_2326', 'w_2327', 'w_2328', 'w_2329', 'w_2330', 'w_2331', 'w_2332', 'w_2333', 'w_2334', 'w_2335', 'w_2336', 'w_2337', 'w_2338', 'w_2339', 'w_2340', 'w_2341', 'w_2342', 'w_2343', 'w_2344', 'w_2345', 'w_2346', 'w_2347', 'w_2348', 'w_2349', 'w_2350', 'w_2351', 'w_2352', 'w_2353', 'w_2354', 'w_2355', 'w_2356', 'w_2357', 'w_2358', 'w_2359', 'w_2360', 'w_2361', 'w_2362', 'w_2363', 'w_2364', 'w_2365', 'w_2366', 'w_2367', 'w_2368', 'w_2369', 'w_2370', 'w_2371', 'w_2372', 'w_2373', 'w_2374', 'w_2375', 'w_2376', 'w_2377', 'w_2378', 'w_2379', 'w_2380', 'w_2381', 'w_2382', 'w_2383', 'w_2384', 'w_2385', 'w_2386', 'w_2387', 'w_2388', 'w_2389', 'w_2390', 'w_2391', 'w_2392', 'w_2393', 'w_2394', 'w_2395', 'w_2396', 'w_2397', 'w_2398', 'w_2399', 'w_2400', 'w_2401', 'w_2402', 'w_2403', 'w_2404', 'w_2405', 'w_2406', 'w_2407', 'w_2408', 'w_2409', 'w_2410', 'w_2411', 'w_2412', 'w_2413', 'w_2414', 'w_2415', 'w_2416', 'w_2417', 'w_2418', 'w_2419', 'w_2420', 'w_2421', 'w_2422', 'w_2423', 'w_2424', 'w_2425', 'w_2426', 'w_2427', 'w_2428', 'w_2429', 'w_2430', 'w_2431', 'w_2432', 'w_2433', 'w_2434', 'w_2435', 'w_2436', 'w_2437', 'w_2438', 'w_2439', 'w_2440', 'w_2441', 'w_2442', 'w_2443', 'w_2444', 'w_2445', 'w_2446', 'w_2447', 'w_2448', 'w_2449', 'w_2450', 'w_2451', 'w_2452', 'w_2453', 'w_2454', 'w_2455', 'w_2456', 'w_2457', 'w_2458', 'w_2459', 'w_2460', 'w_2461', 'w_2462', 'w_2463', 'w_2464', 'w_2465', 'w_2466', 'w_2467', 'w_2468', 'w_2469', 'w_2470', 'w_2471', 'w_2472', 'w_2473', 'w_2474', 'w_2475', 'w_2476', 'w_2477', 'w_2478', 'w_2479', 'w_2480', 'w_2481', 'w_2482', 'w_2483', 'w_2484', 'w_2485', 'w_2486', 'w_2487', 'w_2488', 'w_2489', 'w_2490', 'w_2491', 'w_2492', 'w_2493', 'w_2494', 'w_2495', 'w_2496', 'w_2497', 'w_2498', 'w_2499', 'w_2500', 'w_2501', 'w_2502', 'w_2503', 'w_2504', 'w_2505', 'w_2506', 'w_2507', 'w_2508', 'w_2509', 'w_2510', 'w_2511', 'w_2512', 'w_2513', 'w_2514', 'w_2515', 'w_2516', 'w_2517', 'w_2518', 'w_2519', 'w_2520', 'w_2521', 'w_2522', 'w_2523', 'w_2524', 'w_2525', 'w_2526', 'w_2527', 'w_2528', 'w_2529', 'w_2530', 'w_2531', 'w_2532', 'w_2533', 'w_2534', 'w_2535', 'w_2536', 'w_2537', 'w_2538', 'w_2539', 'w_2540', 'w_2541', 'w_2542', 'w_2543', 'w_2544', 'w_2545', 'w_2546', 'w_2547', 'w_2548', 'w_2549', 'w_2550', 'w_2551', 'w_2552', 'w_2553', 'w_2554', 'w_2555', 'w_2556', 'w_2557', 'w_2558', 'w_2559', 'w_2560', 'w_2561', 'w_2562', 'w_2563', 'w_2564', 'w_2565', 'w_2566', 'w_2567', 'w_2568', 'w_2569', 'w_2570', 'w_2571', 'w_2572', 'w_2573', 'w_2574', 'w_2575', 'w_2576', 'w_2577', 'w_2578', 'w_2579', 'w_2580', 'w_2581', 'w_2582', 'w_2583', 'w_2584', 'w_2585', 'w_2586', 'w_2587', 'w_2588', 'w_2589', 'w_2590', 'w_2591', 'w_2592', 'w_2593', 'w_2594', 'w_2595', 'w_2596', 'w_2597', 'w_2598', 'w_2599', 'w_2600', 'w_2601', 'w_2602', 'w_2603', 'w_2604', 'w_2605', 'w_2606', 'w_2607', 'w_2608', 'w_2609', 'w_2610', 'w_2611', 'w_2612', 'w_2613', 'w_2614', 'w_2615', 'w_2616', 'w_2617', 'w_2618', 'w_2619', 'w_2620', 'w_2621', 'w_2622', 'w_2623', 'w_2624', 'w_2625', 'w_2626', 'w_2627', 'w_2628', 'w_2629', 'w_2630', 'w_2631', 'w_2632', 'w_2633', 'w_2634', 'w_2635', 'w_2636', 'w_2637', 'w_2638', 'w_2639', 'w_2640', 'w_2641', 'w_2642', 'w_2643', 'w_2644', 'w_2645', 'w_2646', 'w_2647', 'w_2648', 'w_2649', 'w_2650', 'w_2651', 'w_2652', 'w_2653', 'w_2654', 'w_2655', 'w_2656', 'w_2657', 'w_2658', 'w_2659', 'w_2660', 'w_2661', 'w_2662', 'w_2663', 'w_2664', 'w_2665', 'w_2666', 'w_2667', 'w_2668', 'w_2669', 'w_2670', 'w_2671', 'w_2672', 'w_2673', 'w_2674', 'w_2675', 'w_2676', 'w_2677', 'w_2678', 'w_2679', 'w_2680', 'w_2681', 'w_2682', 'w_2683', 'w_2684', 'w_2685', 'w_2686', 'w_2687', 'w_2688', 'w_2689', 'w_2690', 'w_2691', 'w_2692', 'w_2693', 'w_2694', 'w_2695', 'w_2696', 'w_2697', 'w_2698', 'w_2699', 'w_2700', 'w_2701', 'w_2702', 'w_2703', 'w_2704', 'w_2705', 'w_2706', 'w_2707', 'w_2708', 'w_2709', 'w_2710', 'w_2711', 'w_2712', 'w_2713', 'w_2714', 'w_2715', 'w_2716', 'w_2717', 'w_2718', 'w_2719', 'w_2720', 'w_2721', 'w_2722', 'w_2723', 'w_2724', 'w_2725', 'w_2726', 'w_2727', 'w_2728', 'w_2729', 'w_2730', 'w_2731', 'w_2732', 'w_2733', 'w_2734', 'w_2735', 'w_2736', 'w_2737', 'w_2738', 'w_2739', 'w_2740', 'w_2741', 'w_2742', 'w_2743', 'w_2744', 'w_2745', 'w_2746', 'w_2747', 'w_2748', 'w_2749', 'w_2750', 'w_2751', 'w_2752', 'w_2753', 'w_2754', 'w_2755', 'w_2756', 'w_2757', 'w_2758', 'w_2759', 'w_2760', 'w_2761', 'w_2762', 'w_2763', 'w_2764', 'w_2765', 'w_2766', 'w_2767', 'w_2768', 'w_2769', 'w_2770', 'w_2771', 'w_2772', 'w_2773', 'w_2774', 'w_2775', 'w_2776', 'w_2777', 'w_2778', 'w_2779', 'w_2780', 'w_2781', 'w_2782', 'w_2783', 'w_2784', 'w_2785', 'w_2786', 'w_2787', 'w_2788', 'w_2789', 'w_2790', 'w_2791', 'w_2792', 'w_2793', 'w_2794', 'w_2795', 'w_2796', 'w_2797', 'w_2798', 'w_2799', 'w_2800', 'w_2801', 'w_2802', 'w_2803', 'w_2804', 'w_2805', 'w_2806', 'w_2807', 'w_2808', 'w_2809', 'w_2810', 'w_2811', 'w_2812', 'w_2813', 'w_2814', 'w_2815', 'w_2816', 'w_2817', 'w_2818', 'w_2819', 'w_2820', 'w_2821', 'w_2822', 'w_2823', 'w_2824', 'w_2825', 'w_2826', 'w_2827', 'w_2828', 'w_2829', 'w_2830', 'w_2831', 'w_2832', 'w_2833', 'w_2834', 'w_2835', 'w_2836', 'w_2837', 'w_2838', 'w_2839', 'w_2840', 'w_2841', 'w_2842', 'w_2843', 'w_2844', 'w_2845', 'w_2846', 'w_2847', 'w_2848', 'w_2849', 'w_2850', 'w_2851', 'w_2852', 'w_2853', 'w_2854', 'w_2855', 'w_2856', 'w_2857', 'w_2858', 'w_2859', 'w_2860', 'w_2861', 'w_2862', 'w_2863', 'w_2864', 'w_2865', 'w_2866', 'w_2867', 'w_2868', 'w_2869', 'w_2870', 'w_2871', 'w_2872', 'w_2873', 'w_2874', 'w_2875', 'w_2876', 'w_2877', 'w_2878', 'w_2879', 'w_2880', 'w_2881', 'w_2882', 'w_2883', 'w_2884', 'w_2885', 'w_2886', 'w_2887', 'w_2888', 'w_2889', 'w_2890', 'w_2891', 'w_2892', 'w_2893', 'w_2894', 'w_2895', 'w_2896', 'w_2897', 'w_2898', 'w_2899', 'w_2900', 'w_2901', 'w_2902', 'w_2903', 'w_2904', 'w_2905', 'w_2906', 'w_2907', 'w_2908', 'w_2909', 'w_2910', 'w_2911', 'w_2912', 'w_2913', 'w_2914', 'w_2915', 'w_2916', 'w_2917', 'w_2918', 'w_2919', 'w_2920', 'w_2921', 'w_2922', 'w_2923', 'w_2924', 'w_2925', 'w_2926', 'w_2927', 'w_2928', 'w_2929', 'w_2930', 'w_2931', 'w_2932', 'w_2933', 'w_2934', 'w_2935', 'w_2936', 'w_2937', 'w_2938', 'w_2939', 'w_2940', 'w_2941', 'w_2942', 'w_2943', 'w_2944', 'w_2945', 'w_2946', 'w_2947', 'w_2948', 'w_2949', 'w_2950', 'w_2951', 'w_2952', 'w_2953', 'w_2954', 'w_2955', 'w_2956', 'w_2957', 'w_2958', 'w_2959', 'w_2960', 'w_2961', 'w_2962', 'w_2963', 'w_2964', 'w_2965', 'w_2966', 'w_2967', 'w_2968', 'w_2969', 'w_2970', 'w_2971', 'w_2972', 'w_2973', 'w_2974', 'w_2975', 'w_2976', 'w_2977', 'w_2978', 'w_2979', 'w_2980', 'w_2981', 'w_2982', 'w_2983', 'w_2984', 'w_2985', 'w_2986', 'w_2987', 'w_2988', 'w_2989', 'w_2990', 'w_2991', 'w_2992', 'w_2993', 'w_2994', 'w_2995', 'w_2996', 'w_2997', 'w_2998', 'w_2999', 'w_3000', 'w_3001', 'w_3002', 'w_3003', 'w_3004', 'w_3005', 'w_3006', 'w_3007', 'w_3008', 'w_3009', 'w_3010', 'w_3011', 'w_3012', 'w_3013', 'w_3014', 'w_3015', 'w_3016', 'w_3017', 'w_3018', 'w_3019', 'w_3020', 'w_3021', 'w_3022', 'w_3023', 'w_3024', 'w_3025', 'w_3026', 'w_3027', 'w_3028', 'w_3029', 'w_3030', 'w_3031', 'w_3032', 'w_3033', 'w_3034', 'w_3035', 'w_3036', 'w_3037', 'w_3038', 'w_3039', 'w_3040', 'w_3041', 'w_3042', 'w_3043', 'w_3044', 'w_3045', 'w_3046', 'w_3047', 'w_3048', 'w_3049', 'w_3050', 'w_3051', 'w_3052', 'w_3053', 'w_3054', 'w_3055', 'w_3056', 'w_3057', 'w_3058', 'w_3059', 'w_3060', 'w_3061', 'w_3062', 'w_3063', 'w_3064', 'w_3065', 'w_3066', 'w_3067', 'w_3068', 'w_3069', 'w_3070', 'w_3071', 'w_3072', 'w_3073', 'w_3074', 'w_3075', 'w_3076', 'w_3077', 'w_3078', 'w_3079', 'w_3080', 'w_3081', 'w_3082', 'w_3083', 'w_3084', 'w_3085', 'w_3086', 'w_3087', 'w_3088', 'w_3089', 'w_3090', 'w_3091', 'w_3092', 'w_3093', 'w_3094', 'w_3095', 'w_3096', 'w_3097', 'w_3098', 'w_3099', 'w_3100', 'w_3101', 'w_3102', 'w_3103', 'w_3104', 'w_3105', 'w_3106', 'w_3107', 'w_3108', 'w_3109', 'w_3110', 'w_3111', 'w_3112', 'w_3113', 'w_3114', 'w_3115', 'w_3116', 'w_3117', 'w_3118', 'w_3119', 'w_3120', 'w_3121', 'w_3122', 'w_3123', 'w_3124', 'w_3125', 'w_3126', 'w_3127', 'w_3128', 'w_3129', 'w_3130', 'w_3131', 'w_3132', 'w_3133', 'w_3134', 'w_3135', 'w_3136', 'w_3137', 'w_3138', 'w_3139', 'w_3140', 'w_3141', 'w_3142', 'w_3143', 'w_3144', 'w_3145', 'w_3146', 'w_3147', 'w_3148', 'w_3149', 'w_3150', 'w_3151', 'w_3152', 'w_3153', 'w_3154', 'w_3155', 'w_3156', 'w_3157', 'w_3158', 'w_3159', 'w_3160', 'w_3161', 'w_3162', 'w_3163', 'w_3164', 'w_3165', 'w_3166', 'w_3167', 'w_3168', 'w_3169', 'w_3170', 'w_3171', 'w_3172', 'w_3173', 'w_3174', 'w_3175', 'w_3176', 'w_3177', 'w_3178', 'w_3179', 'w_3180', 'w_3181', 'w_3182', 'w_3183', 'w_3184', 'w_3185', 'w_3186', 'w_3187', 'w_3188', 'w_3189', 'w_3190', 'w_3191', 'w_3192', 'w_3193', 'w_3194', 'w_3195', 'w_3196', 'w_3197', 'w_3198', 'w_3199', 'w_3200', 'w_3201', 'w_3202', 'w_3203', 'w_3204', 'w_3205', 'w_3206', 'w_3207', 'w_3208', 'w_3209', 'w_3210', 'w_3211', 'w_3212', 'w_3213', 'w_3214', 'w_3215', 'w_3216', 'w_3217', 'w_3218', 'w_3219', 'w_3220', 'w_3221', 'w_3222', 'w_3223', 'w_3224', 'w_3225', 'w_3226', 'w_3227', 'w_3228', 'w_3229', 'w_3230', 'w_3231', 'w_3232', 'w_3233', 'w_3234', 'w_3235', 'w_3236', 'w_3237', 'w_3238', 'w_3239', 'w_3240', 'w_3241', 'w_3242', 'w_3243', 'w_3244', 'w_3245', 'w_3246', 'w_3247', 'w_3248', 'w_3249', 'w_3250', 'w_3251', 'w_3252', 'w_3253', 'w_3254', 'w_3255', 'w_3256', 'w_3257', 'w_3258', 'w_3259', 'w_3260', 'w_3261', 'w_3262', 'w_3263', 'w_3264', 'w_3265', 'w_3266', 'w_3267', 'w_3268', 'w_3269', 'w_3270', 'w_3271', 'w_3272', 'w_3273', 'w_3274', 'w_3275', 'w_3276', 'w_3277', 'w_3278', 'w_3279', 'w_3280', 'w_3281', 'w_3282', 'w_3283', 'w_3284', 'w_3285', 'w_3286', 'w_3287', 'w_3288', 'w_3289', 'w_3290', 'w_3291', 'w_3292', 'w_3293', 'w_3294', 'w_3295', 'w_3296', 'w_3297', 'w_3298', 'w_3299', 'w_3300', 'w_3301', 'w_3302', 'w_3303', 'w_3304', 'w_3305', 'w_3306', 'w_3307', 'w_3308', 'w_3309', 'w_3310', 'w_3311', 'w_3312', 'w_3313', 'w_3314', 'w_3315', 'w_3316', 'w_3317', 'w_3318', 'w_3319', 'w_3320', 'w_3321', 'w_3322', 'w_3323', 'w_3324', 'w_3325', 'w_3326', 'w_3327', 'w_3328', 'w_3329', 'w_3330', 'w_3331', 'w_3332', 'w_3333', 'w_3334', 'w_3335', 'w_3336', 'w_3337', 'w_3338', 'w_3339', 'w_3340', 'w_3341', 'w_3342', 'w_3343', 'w_3344', 'w_3345', 'w_3346', 'w_3347', 'w_3348', 'w_3349', 'w_3350', 'w_3351', 'w_3352', 'w_3353', 'w_3354', 'w_3355', 'w_3356', 'w_3357', 'w_3358', 'w_3359', 'w_3360', 'w_3361', 'w_3362', 'w_3363', 'w_3364', 'w_3365', 'w_3366', 'w_3367', 'w_3368', 'w_3369', 'w_3370', 'w_3371', 'w_3372', 'w_3373', 'w_3374', 'w_3375', 'w_3376', 'w_3377', 'w_3378', 'w_3379', 'w_3380', 'w_3381', 'w_3382', 'w_3383', 'w_3384', 'w_3385', 'w_3386', 'w_3387', 'w_3388', 'w_3389', 'w_3390', 'w_3391', 'w_3392', 'w_3393', 'w_3394', 'w_3395', 'w_3396', 'w_3397', 'w_3398', 'w_3399', 'w_3400', 'w_3401', 'w_3402', 'w_3403', 'w_3404', 'w_3405', 'w_3406', 'w_3407', 'w_3408', 'w_3409', 'w_3410', 'w_3411', 'w_3412', 'w_3413', 'w_3414', 'w_3415', 'w_3416', 'w_3417', 'w_3418', 'w_3419', 'w_3420', 'w_3421', 'w_3422', 'w_3423', 'w_3424', 'w_3425', 'w_3426', 'w_3427', 'w_3428', 'w_3429', 'w_3430', 'w_3431', 'w_3432', 'w_3433', 'w_3434', 'w_3435', 'w_3436', 'w_3437', 'w_3438', 'w_3439', 'w_3440', 'w_3441', 'w_3442', 'w_3443', 'w_3444', 'w_3445', 'w_3446', 'w_3447', 'w_3448', 'w_3449', 'w_3450', 'w_3451', 'w_3452', 'w_3453', 'w_3454', 'w_3455', 'w_3456', 'w_3457', 'w_3458', 'w_3459', 'w_3460', 'w_3461', 'w_3462', 'w_3463', 'w_3464', 'w_3465', 'w_3466', 'w_3467', 'w_3468', 'w_3469', 'w_3470', 'w_3471', 'w_3472', 'w_3473', 'w_3474', 'w_3475', 'w_3476', 'w_3477', 'w_3478', 'w_3479', 'w_3480', 'w_3481', 'w_3482', 'w_3483', 'w_3484', 'w_3485', 'w_3486', 'w_3487', 'w_3488', 'w_3489', 'w_3490', 'w_3491', 'w_3492', 'w_3493', 'w_3494', 'w_3495', 'w_3496', 'w_3497', 'w_3498', 'w_3499', 'w_3500', 'w_3501', 'w_3502', 'w_3503', 'w_3504', 'w_3505', 'w_3506', 'w_3507', 'w_3508', 'w_3509', 'w_3510', 'w_3511', 'w_3512', 'w_3513', 'w_3514', 'w_3515', 'w_3516', 'w_3517', 'w_3518', 'w_3519', 'w_3520', 'w_3521', 'w_3522', 'w_3523', 'w_3524', 'w_3525', 'w_3526', 'w_3527', 'w_3528', 'w_3529', 'w_3530', 'w_3531', 'w_3532', 'w_3533', 'w_3534', 'w_3535', 'w_3536', 'w_3537', 'w_3538', 'w_3539', 'w_3540', 'w_3541', 'w_3542', 'w_3543', 'w_3544', 'w_3545', 'w_3546', 'w_3547', 'w_3548', 'w_3549', 'w_3550', 'w_3551', 'w_3552', 'w_3553', 'w_3554', 'w_3555', 'w_3556', 'w_3557', 'w_3558', 'w_3559', 'w_3560', 'w_3561', 'w_3562', 'w_3563', 'w_3564', 'w_3565', 'w_3566', 'w_3567', 'w_3568', 'w_3569', 'w_3570', 'w_3571', 'w_3572', 'w_3573', 'w_3574', 'w_3575', 'w_3576', 'w_3577', 'w_3578', 'w_3579', 'w_3580', 'w_3581', 'w_3582', 'w_3583', 'w_3584', 'w_3585', 'w_3586', 'w_3587', 'w_3588', 'w_3589', 'w_3590', 'w_3591', 'w_3592', 'w_3593', 'w_3594', 'w_3595', 'w_3596', 'w_3597', 'w_3598', 'w_3599', 'w_3600', 'w_3601', 'w_3602', 'w_3603', 'w_3604', 'w_3605', 'w_3606', 'w_3607', 'w_3608', 'w_3609', 'w_3610', 'w_3611', 'w_3612', 'w_3613', 'w_3614', 'w_3615', 'w_3616', 'w_3617', 'w_3618', 'w_3619', 'w_3620', 'w_3621', 'w_3622', 'w_3623', 'w_3624', 'w_3625', 'w_3626', 'w_3627', 'w_3628', 'w_3629', 'w_3630', 'w_3631', 'w_3632', 'w_3633', 'w_3634', 'w_3635', 'w_3636', 'w_3637', 'w_3638', 'w_3639', 'w_3640', 'w_3641', 'w_3642', 'w_3643', 'w_3644', 'w_3645', 'w_3646', 'w_3647', 'w_3648', 'w_3649', 'w_3650', 'w_3651', 'w_3652', 'w_3653', 'w_3654', 'w_3655', 'w_3656', 'w_3657', 'w_3658', 'w_3659', 'w_3660', 'w_3661', 'w_3662', 'w_3663', 'w_3664', 'w_3665', 'w_3666', 'w_3667', 'w_3668', 'w_3669', 'w_3670', 'w_3671', 'w_3672', 'w_3673', 'w_3674', 'w_3675', 'w_3676', 'w_3677', 'w_3678', 'w_3679', 'w_3680', 'w_3681', 'w_3682', 'w_3683', 'w_3684', 'w_3685', 'w_3686', 'w_3687', 'w_3688', 'w_3689', 'w_3690', 'w_3691', 'w_3692', 'w_3693', 'w_3694', 'w_3695', 'w_3696', 'w_3697', 'w_3698', 'w_3699', 'w_3700', 'w_3701', 'w_3702', 'subject']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>w_0</th>\n",
              "      <th>w_1</th>\n",
              "      <th>w_2</th>\n",
              "      <th>w_3</th>\n",
              "      <th>w_4</th>\n",
              "      <th>w_5</th>\n",
              "      <th>w_6</th>\n",
              "      <th>w_7</th>\n",
              "      <th>w_8</th>\n",
              "      <th>w_9</th>\n",
              "      <th>w_10</th>\n",
              "      <th>w_11</th>\n",
              "      <th>w_12</th>\n",
              "      <th>w_13</th>\n",
              "      <th>w_14</th>\n",
              "      <th>w_15</th>\n",
              "      <th>w_16</th>\n",
              "      <th>w_17</th>\n",
              "      <th>w_18</th>\n",
              "      <th>w_19</th>\n",
              "      <th>w_20</th>\n",
              "      <th>w_21</th>\n",
              "      <th>w_22</th>\n",
              "      <th>w_23</th>\n",
              "      <th>w_24</th>\n",
              "      <th>w_25</th>\n",
              "      <th>w_26</th>\n",
              "      <th>w_27</th>\n",
              "      <th>w_28</th>\n",
              "      <th>w_29</th>\n",
              "      <th>w_30</th>\n",
              "      <th>w_31</th>\n",
              "      <th>w_32</th>\n",
              "      <th>w_33</th>\n",
              "      <th>w_34</th>\n",
              "      <th>w_35</th>\n",
              "      <th>w_36</th>\n",
              "      <th>w_37</th>\n",
              "      <th>w_38</th>\n",
              "      <th>w_39</th>\n",
              "      <th>...</th>\n",
              "      <th>w_3664</th>\n",
              "      <th>w_3665</th>\n",
              "      <th>w_3666</th>\n",
              "      <th>w_3667</th>\n",
              "      <th>w_3668</th>\n",
              "      <th>w_3669</th>\n",
              "      <th>w_3670</th>\n",
              "      <th>w_3671</th>\n",
              "      <th>w_3672</th>\n",
              "      <th>w_3673</th>\n",
              "      <th>w_3674</th>\n",
              "      <th>w_3675</th>\n",
              "      <th>w_3676</th>\n",
              "      <th>w_3677</th>\n",
              "      <th>w_3678</th>\n",
              "      <th>w_3679</th>\n",
              "      <th>w_3680</th>\n",
              "      <th>w_3681</th>\n",
              "      <th>w_3682</th>\n",
              "      <th>w_3683</th>\n",
              "      <th>w_3684</th>\n",
              "      <th>w_3685</th>\n",
              "      <th>w_3686</th>\n",
              "      <th>w_3687</th>\n",
              "      <th>w_3688</th>\n",
              "      <th>w_3689</th>\n",
              "      <th>w_3690</th>\n",
              "      <th>w_3691</th>\n",
              "      <th>w_3692</th>\n",
              "      <th>w_3693</th>\n",
              "      <th>w_3694</th>\n",
              "      <th>w_3695</th>\n",
              "      <th>w_3696</th>\n",
              "      <th>w_3697</th>\n",
              "      <th>w_3698</th>\n",
              "      <th>w_3699</th>\n",
              "      <th>w_3700</th>\n",
              "      <th>w_3701</th>\n",
              "      <th>w_3702</th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100157</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Agents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100598</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105684</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Agents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114091</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>AI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zhang99query</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zhang99situated</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ML</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zhang99towards</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zhou00implementation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455346</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ML</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3312 rows × 3704 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      w_0  w_1  w_2  w_3  ...  w_3700  w_3701  w_3702  subject\n",
              "100157                  0    0    0    0  ...       0       0       0   Agents\n",
              "100598                  0    0    0    0  ...       0       0       0       IR\n",
              "105684                  0    1    0    0  ...       0       0       0   Agents\n",
              "11099                   0    0    0    0  ...       0       0       0       DB\n",
              "114091                  0    0    0    0  ...       0       0       0       AI\n",
              "...                   ...  ...  ...  ...  ...     ...     ...     ...      ...\n",
              "zhang99query            0    0    0    0  ...       0       0       0       DB\n",
              "zhang99situated         0    0    0    0  ...       0       0       0       ML\n",
              "zhang99towards          0    0    0    0  ...       0       0       0       IR\n",
              "zhou00implementation    0    0    0    0  ...       0       0       0       DB\n",
              "455346                  0    0    0    0  ...       0       0       0       ML\n",
              "\n",
              "[3312 rows x 3704 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7nShK_TdeTQ"
      },
      "source": [
        "if df_data =='cora' or 'citeseer':\n",
        "  df['subject'],_ = pd.factorize(df['subject'])\n",
        "if df_data =='reuters':\n",
        "  df['label'],_ = pd.factorize(df['label'])\n",
        "df_np = df.to_numpy()\n",
        "df_X = pd.DataFrame(df_np[:, :-1])\n",
        "df_y = pd.DataFrame(df_np[:, -1:])\n",
        "# data = get_data(df_X,df_y)\n",
        "log_path = './result/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymfWfWGIAoIO"
      },
      "source": [
        "np.savetxt(fname='citeseer.txt',X=df_np[:50],delimiter='  ',fmt='%1.1f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a6nqcRtkxm0"
      },
      "source": [
        "# np.savetxt(fname='cora.txt',X=df_np[:df_np.shape[0]//20],delimiter='  ',fmt='%1.1f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMHCp--QBcmj"
      },
      "source": [
        "np.savetxt(fname='reuters.txt',X=df_np[:500],delimiter='  ',fmt='%1.1f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB-BgF9VyQpH"
      },
      "source": [
        "filename = df_data+'_GRAPE'\n",
        "save_obj(data,filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Ddc-6tylNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9355b5-b600-439d-dfff-9a1a07de242c"
      },
      "source": [
        "!zip ./cora_GRAPE.zip ./cora_GRAPE.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: cora_GRAPE.pkl (deflated 97%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdqCUqqH7H5Z"
      },
      "source": [
        "# Building the Model (*In Progress....*)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1kIQ4QoSsX"
      },
      "source": [
        "def get_activation(activation):\n",
        "    if activation == 'relu':\n",
        "        return torch.nn.ReLU()\n",
        "    elif activation == 'prelu':\n",
        "        return torch.nn.PReLU()\n",
        "    elif activation == 'tanh':\n",
        "        return torch.nn.Tanh()\n",
        "    elif (activation is None) or (activation == 'none'):\n",
        "        return torch.nn.Identity()\n",
        "    else:\n",
        "        raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgXRaCI-a6i8"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "class GNNTextData(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "                node_input_dim, edge_input_dim,\n",
        "                node_dim, edge_dim, edge_mode,\n",
        "                model_types, dropout, activation,\n",
        "                concat_states, node_post_mlp_hiddens,\n",
        "                normalize_embs, aggr\n",
        "                ):\n",
        "        super(GNNTextData, self).__init__()\n",
        "        # self.dropout = dropout\n",
        "        # self.activation = activation\n",
        "        self.concat_states = concat_states\n",
        "        self.model_types = model_types\n",
        "        self.gnn_layer_num = len(model_types)\n",
        "\n",
        "        # convs\n",
        "        self.convs = self.build_convs(node_input_dim, edge_input_dim,\n",
        "                                    node_dim, edge_dim, edge_mode,\n",
        "                                    model_types, normalize_embs, activation, aggr)\n",
        "\n",
        "        # post node update\n",
        "        if concat_states:\n",
        "            self.node_post_mlp = self.build_node_post_mlp(int(node_dim*len(model_types)), int(node_dim*len(model_types)), node_post_mlp_hiddens, dropout, activation)\n",
        "        else:\n",
        "            self.node_post_mlp = self.build_node_post_mlp(node_dim, node_dim, node_post_mlp_hiddens, dropout, activation)\n",
        "\n",
        "        self.edge_update_mlps = self.build_edge_update_mlps(node_dim, edge_input_dim, edge_dim, self.gnn_layer_num, activation)\n",
        "\n",
        "    def build_node_post_mlp(self, input_dim, output_dim, hidden_dims, dropout, activation):\n",
        "        if 0 in hidden_dims:\n",
        "            return get_activation('none')\n",
        "        else:\n",
        "            layers = []\n",
        "            for hidden_dim in hidden_dims:\n",
        "                layer = nn.Sequential(\n",
        "                            nn.Linear(input_dim, hidden_dim),\n",
        "                            get_activation(activation),\n",
        "                            nn.Dropout(dropout),\n",
        "                            )\n",
        "                layers.append(layer)\n",
        "                input_dim = hidden_dim\n",
        "            layer = nn.Linear(input_dim, output_dim)\n",
        "            layers.append(layer)\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "    def build_convs(self, node_input_dim, edge_input_dim,\n",
        "                     node_dim, edge_dim, edge_mode,\n",
        "                     model_types, normalize_embs, activation, aggr):\n",
        "        convs = nn.ModuleList()\n",
        "        conv = self.build_conv_model(model_types[0],node_input_dim,node_dim,\n",
        "                                    edge_input_dim, edge_mode, normalize_embs[0], activation, aggr)\n",
        "        convs.append(conv)\n",
        "        for l in range(1,len(model_types)):\n",
        "            conv = self.build_conv_model(model_types[l],node_dim, node_dim,\n",
        "                                    edge_dim, edge_mode, normalize_embs[l], activation, aggr)\n",
        "            convs.append(conv)\n",
        "        return convs\n",
        "\n",
        "    def build_conv_model(self, model_type, node_in_dim, node_out_dim, edge_dim, edge_mode, normalize_emb, activation, aggr):\n",
        "        #print(model_type)\n",
        "        if model_type == 'GCN':\n",
        "            return pyg_nn.GCNConv(node_in_dim,node_out_dim)\n",
        "        elif model_type == 'GraphSage':\n",
        "            return pyg_nn.SAGEConv(node_in_dim,node_out_dim)\n",
        "        elif model_type == 'GAT':\n",
        "            return pyg_nn.GATConv(node_in_dim,node_out_dim)\n",
        "\n",
        "\n",
        "    def build_edge_update_mlps(self, node_dim, edge_input_dim, edge_dim, gnn_layer_num, activation):\n",
        "        edge_update_mlps = nn.ModuleList()\n",
        "        edge_update_mlp = nn.Sequential(\n",
        "                nn.Linear(node_dim+node_dim+edge_input_dim,edge_dim),\n",
        "                get_activation(activation),\n",
        "                )\n",
        "        edge_update_mlps.append(edge_update_mlp)\n",
        "        for l in range(1,gnn_layer_num):\n",
        "            edge_update_mlp = nn.Sequential(\n",
        "                nn.Linear(node_dim+node_dim+edge_dim,edge_dim),\n",
        "                get_activation(activation),\n",
        "                )\n",
        "            edge_update_mlps.append(edge_update_mlp)\n",
        "        return edge_update_mlps\n",
        "\n",
        "    def update_edge_attr(self, x, edge_attr, edge_index, mlp):\n",
        "        x_i = x[edge_index[0],:]\n",
        "        x_j = x[edge_index[1],:]\n",
        "        edge_attr = mlp(torch.cat((x_i,x_j,edge_attr),dim=-1))\n",
        "        return edge_attr\n",
        "\n",
        "    def forward(self, x, edge_attr, edge_index):\n",
        "        if self.concat_states:\n",
        "            concat_x = []\n",
        "        for l,(conv_name,conv) in enumerate(zip(self.model_types,self.convs)):\n",
        "            # self.check_input(x,edge_attr,edge_index)\n",
        "            if conv_name == 'EGCN' or conv_name == 'EGSAGE':\n",
        "                x = conv(x, edge_attr, edge_index)\n",
        "            else:\n",
        "                x = conv(x, edge_index)\n",
        "            if self.concat_states:\n",
        "                concat_x.append(x)\n",
        "            edge_attr = self.update_edge_attr(x, edge_attr, edge_index, self.edge_update_mlps[l])\n",
        "            #print(edge_attr.shape)\n",
        "        if self.concat_states:\n",
        "            x = torch.cat(concat_x, 1)\n",
        "        x = self.node_post_mlp(x)\n",
        "        # self.check_input(x,edge_attr,edge_index)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUtrc8aIcV-a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class MLPNet(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "         \t\tinput_dims, output_dim,\n",
        "         \t\thidden_layer_sizes=(64,),\n",
        "         \t\thidden_activation='relu',\n",
        "         \t\toutput_activation=None,\n",
        "                dropout=0.):\n",
        "        super(MLPNet, self).__init__()\n",
        "\n",
        "        layers = nn.ModuleList()\n",
        "\n",
        "        input_dim = np.sum(input_dims)\n",
        "\n",
        "        for layer_size in hidden_layer_sizes:\n",
        "        \thidden_dim = layer_size\n",
        "        \tlayer = nn.Sequential(\n",
        "        \t\t\t\tnn.Linear(input_dim, hidden_dim),\n",
        "        \t\t\t\tget_activation(hidden_activation),\n",
        "        \t\t\t\tnn.Dropout(dropout),\n",
        "        \t\t\t\t)\n",
        "        \tlayers.append(layer)\n",
        "        \tinput_dim = hidden_dim\n",
        "\n",
        "        layer = nn.Sequential(\n",
        "        \t\t\t\tnn.Linear(input_dim, output_dim),\n",
        "        \t\t\t\tget_activation(output_activation),\n",
        "        \t\t\t\t)\n",
        "       \tlayers.append(layer)\n",
        "       \tself.layers = layers\n",
        "\n",
        "    def forward(self, inputs):\n",
        "    \tif torch.is_tensor(inputs):\n",
        "    \t\tinputs = [inputs]\n",
        "    \tinput_var = torch.cat(inputs,-1)\n",
        "    \tfor layer in self.layers:\n",
        "    \t\tinput_var = layer(input_var)\n",
        "    \treturn input_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_LxjEpldlzI"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  cuda = auto_select_gpu()\n",
        "  device = torch.device('cuda:{}'.format(cuda))\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "model = GNNTextData()\n",
        "impute_model = MLPNet(input_dims=128, output_dim=1).to(device)\n",
        "\n",
        "trainable_parameters = list(impute_model.parameters())\n",
        "print(\"total trainable_parameters: \",len(trainable_parameters))\n",
        "\n",
        "# train\n",
        "Train_loss = []\n",
        "Test_rmse = []\n",
        "Test_l1 = []\n",
        "Lr = []\n",
        "\n",
        "x = data.x.clone().detach().to(device)\n",
        "all_train_edge_index = data.train_edge_index.clone().detach().to(device)\n",
        "all_train_edge_attr = data.train_edge_attr.clone().detach().to(device)\n",
        "all_train_labels = data.train_labels.clone().detach().to(device)\n",
        "test_input_edge_index = all_train_edge_index\n",
        "test_input_edge_attr = all_train_edge_attr\n",
        "test_edge_index = data.test_edge_index.clone().detach().to(device)\n",
        "test_edge_attr = data.test_edge_attr.clone().detach().to(device)\n",
        "test_labels = data.test_labels.clone().detach().to(device)\n",
        "\n",
        "train_edge_index, train_edge_attr, train_labels =\\\n",
        "             all_train_edge_index, all_train_edge_index, all_train_labels\n",
        "print(\"train edge num is {}, test edge num is input {}, output {}\"\\\n",
        "                .format(\n",
        "                all_train_edge_index.shape[0],\n",
        "                test_input_edge_attr.shape[0], test_edge_attr.shape[0]))\n",
        "\n",
        "learning_rate = 0.00002\n",
        "optimizer = opt.Adam(impute_model.parameters(), learning_rate)\n",
        "\n",
        "for epoch in range(1000):\n",
        "   \n",
        "  #  impute_model.train()\n",
        "   optimizer.zero_grad()\n",
        "   pred = impute_model([x_embd[train_edge_index[0]], x_embd[train_edge_index[1]]])\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   loss = F.mse_loss(pred_train, label_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4G-fxJtd9J7"
      },
      "source": [
        "impute_model.eval()\n",
        "with torch.no_grad():\n",
        "  pred = impute_model([x_embd[valid_edge_index[0], :], x_embd[valid_edge_index[1], :]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2q2tSdhfDZD"
      },
      "source": [
        "# pred_train = pred_train.detach().cpu().numpy()\n",
        "# label_train = label_train.detach().cpu().numpy()\n",
        "# pred_test = pred_test.detach().cpu().numpy()\n",
        "# label_test = label_test.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdqOWaDG680t"
      },
      "source": [
        "# **GRAPE Result & Other Baselines**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh2lSd_nqbJ-",
        "cellView": "form"
      },
      "source": [
        "#@title function : load / save pickle_obj\n",
        "import pickle\n",
        "\n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a51s0DsascQe"
      },
      "source": [
        "import os\n",
        "from utils.plot_utils import plot_curve, plot_sample\n",
        "log_path = './results_all/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCR0zwlsKnT"
      },
      "source": [
        "model_result = load_obj('uci/test/concrete/0/result')\n",
        "\n",
        "def get_load_obj(baseline_name):\n",
        "  return load_obj('/content/GRAPE/uci/mdi_results/results/'+baseline_name+'/concrete/0/result')\n",
        "\n",
        "obj = model_result\n",
        "names = []\n",
        "\n",
        "plot_curve(obj['curves'], log_path+'curves.png',keys=None, \n",
        "                clip=True, label_min=True, label_end=True)\n",
        "plot_curve(obj, log_path+'lr.png',keys=['lr'], \n",
        "            clip=False, label_min=False, label_end=False)\n",
        "plot_sample(obj['outputs'], log_path+'outputs.png', \n",
        "            groups=[['final_pred_train','label_train'],\n",
        "                        ['final_pred_test','label_test']\n",
        "                        ], \n",
        "                num_points=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRw_kwf03F4I"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plotCurve(data,keys=None,clip=True, label_min=True, label_end=True):\n",
        "    if not keys:\n",
        "        keys = data.keys()\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i,key in enumerate(keys):\n",
        "        if key == 'train_loss':\n",
        "          continue\n",
        "        plt.subplot(len(keys),1,i+1)\n",
        "        if clip:\n",
        "            limit = 2*np.mean(np.abs(data[key]))\n",
        "            y = np.clip(data[key],-limit,limit)\n",
        "        else:\n",
        "            y = data[key]\n",
        "        plt.plot(y, linewidth=1.,label=key)\n",
        "        if label_min:\n",
        "            plt.plot(np.argmin(data[key]),np.min(data[key]),'o',\n",
        "                    label=\"min: {:.3g}\".format(np.min(data[key])))\n",
        "        if label_end:\n",
        "            plt.plot(len(data[key])-1,data[key][-1],'o',\n",
        "                    label=\"end: {:.3g}\".format(data[key][-1]))\n",
        "        plt.legend()        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LKTVSDIyAMM"
      },
      "source": [
        "baseline_models= ['knn_v1','mean_v1','svd_v1','spectral_v1']\n",
        "for b in baseline_models:\n",
        "  baseline = get_load_obj(b)\n",
        "  print(b,\" (rmse) : \",baseline['rmse'])\n",
        "  print(b,\" (mae) : \",baseline['mae'])\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdjTmcGA3YRQ"
      },
      "source": [
        "plotCurve(obj['curves'],keys=None,clip=True, label_min=True, label_end=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLsLtwK67THF"
      },
      "source": [
        "!zip -r ./results_all.zip ./results_all/\n",
        "!zip -r ./baseline_results_all.zip ./uci/mdi_results/results/\n",
        "!zip -r ./model_results.zip  ./uci/test/concrete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQpKzakE75Vb"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"./results_all.zip\")\n",
        "files.download(\"./baseline_results_all.zip\")\n",
        "files.download(\"./model_results.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}